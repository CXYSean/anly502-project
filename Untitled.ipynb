{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-34-85.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = sc.sequenceFile(\"s3://datasets.elasticmapreduce/ngrams/books/20090715/eng-fiction-all/1gram/data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[2] at mapPartitions at SerDeUtil.scala:244"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(t):\n",
    "    tmp = t[1]\n",
    "    return tmp.split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram1 = ngram.map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#', '1594', '1', '1', '1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram1.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "gram1 = gram1.map(lambda x:Row(ngram=x[0],year=x[1],occurrences=x[2],pages=x[3],books=x[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "     .appName(\"Test SparkSession\") \\\n",
    "     .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(gram1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----------+-----+----+\n",
      "|books|ngram|occurrences|pages|year|\n",
      "+-----+-----+-----------+-----+----+\n",
      "|    1|    #|          1|    1|1594|\n",
      "|    1|    #|          1|    1|1605|\n",
      "|    1|    #|          3|    3|1613|\n",
      "|    1|    #|          2|    2|1634|\n",
      "|    1|    #|          3|    2|1637|\n",
      "|    1|    #|         19|   16|1639|\n",
      "|    2|    #|          6|    6|1641|\n",
      "|    1|    #|          1|    1|1650|\n",
      "|    1|    #|          1|    1|1652|\n",
      "|    1|    #|          6|    5|1653|\n",
      "+-----+-----+-----------+-----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram2 = sc.sequenceFile(\"s3://datasets.elasticmapreduce/ngrams/books/20090715/eng-fiction-all/2gram/data\")\n",
    "gram2 = gram2.map(mapper)\n",
    "gram2 = gram2.map(lambda x:Row(ngram=x[0],year=x[1],occurrences=x[2],pages=x[3],books=x[4]))\n",
    "df2 = spark.createDataFrame(gram2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----------+-----+----+\n",
      "|books|  ngram|occurrences|pages|year|\n",
      "+-----+-------+-----------+-----+----+\n",
      "|    1|! 00000|          1|    1|1796|\n",
      "|    1|! 00000|          1|    1|1832|\n",
      "|    1|! 00000|          1|    1|1838|\n",
      "|    1|! 00000|          1|    1|1840|\n",
      "|    1|! 00000|          1|    1|1841|\n",
      "|    1|! 00000|          1|    1|1881|\n",
      "|    1|! 00000|          1|    1|1883|\n",
      "|    2|! 00000|          2|    2|1892|\n",
      "|    1|! 00000|          1|    1|1894|\n",
      "|    1|! 00000|          1|    1|1897|\n",
      "+-----+-------+-----------+-----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_1800 = df2.filter(df2.year>=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----------+-----+----+\n",
      "|books|  ngram|occurrences|pages|year|\n",
      "+-----+-------+-----------+-----+----+\n",
      "|    1|! 00000|          1|    1|1832|\n",
      "|    1|! 00000|          1|    1|1838|\n",
      "|    1|! 00000|          1|    1|1840|\n",
      "|    1|! 00000|          1|    1|1841|\n",
      "|    1|! 00000|          1|    1|1881|\n",
      "|    1|! 00000|          1|    1|1883|\n",
      "|    2|! 00000|          2|    2|1892|\n",
      "|    1|! 00000|          1|    1|1894|\n",
      "|    1|! 00000|          1|    1|1897|\n",
      "|    2|! 00000|          2|    2|1900|\n",
      "+-----+-------+-----------+-----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_1800.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_1800_1810 = df2_1800.filter(df2_1800.year<1810)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----------+-----+----+\n",
      "|books|ngram|occurrences|pages|year|\n",
      "+-----+-----+-----------+-----+----+\n",
      "|    1|! 165|          1|    1|1800|\n",
      "|    2|! 165|          2|    2|1804|\n",
      "|    1|! 165|          1|    1|1805|\n",
      "|    1|! 185|          1|    1|1806|\n",
      "|    4|! 185|          4|    4|1807|\n",
      "|    1|! 450|          1|    1|1804|\n",
      "|    2| ! AH|          2|    2|1800|\n",
      "|    2| ! AH|          2|    2|1803|\n",
      "|    2| ! AH|          2|    2|1804|\n",
      "|    1| ! AH|          1|    1|1805|\n",
      "+-----+-----+-----------+-----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_1800_1810.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = df2_1800_1810.groupBy(\"ngram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1800_1810 = group_data.agg({'books':'sum', 'occurrences':'sum', 'pages':'sum'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ngram: string (nullable = true)\n",
      " |-- sum(occurrences): double (nullable = true)\n",
      " |-- sum(books): double (nullable = true)\n",
      " |-- sum(pages): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group1800_1810.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ngram: string, sum(occurrences): double, sum(books): double, sum(pages): double]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1800_1810.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1800_1810 = group1800_1810.withColumnRenamed(\"sum(occurrences)\", \"occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1800_1810 = group1800_1810.withColumnRenamed(\"sum(books)\", \"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1800_1810 = group1800_1810.withColumnRenamed(\"sum(pages)\", \"pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1800_1810.write.parquet(\"s3://chenxiyuanly502/2gram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = spark.read.parquet(\"s3://chenxiyuanly502/2gram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
